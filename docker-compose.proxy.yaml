services:
  open-webui:
      environment:
        - "OPENAI_API_BASE_URL=http://litellm-proxy:8000/v1"
      env_file:
        - .env
      depends_on:
        - litellm-proxy

  litellm-proxy:
      container_name: litellm-proxy
      image: ghcr.io/berriai/litellm:main-v1.40.4
      ports:
        - ${LITELLM_PORT-4000}:8000
      environment:
        - "OPENAI_API_KEY=$OPENAI_API_KEY"
        - "AZURE_API_KEY=$AZURE_API_KEY"
        - "AZURE_DEPLOYMENT_URL=$AZURE_DEPLOYMENT_URL"
      volumes:
        - ./litellm-config.yaml:/app/config.yaml
      command: [ "--config", "/app/config.yaml", "--port", "8000" ]
      restart: unless-stopped